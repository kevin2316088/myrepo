{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevin2316088/myrepo/blob/main/FA_NamesSurnames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GNrOr-WiKQW"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=1DXUVHxd4t15mfuqMgMCLnsP4jWVI5EWz)\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "Â© 2023 Copyright The University of New South Wales - CRICOS 00098G\n",
        "\n",
        "**Authors**: Oscar Perez-Concha.\n",
        "\n",
        "**Communications**: If you have any questions, please email Oscar at: o.perezconcha@unsw.edu.au"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Assignment (FA)"
      ],
      "metadata": {
        "id": "N6T0wwT_GozJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "R1skKevpG0jB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QmhnQ1KbGY0B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN4p9w5eiKQY"
      },
      "source": [
        "#####################################################################################\n",
        "\n",
        "Double-click to write down your name and surname.\n",
        "\n",
        "**Name 1 and Surname 1:**\n",
        "\n",
        "**Honour Pledge** <p>\n",
        "    \n",
        "Declaration: <p>\n",
        "    \n",
        "    \n",
        "I declare that this assessment item is my own work, except where acknowledged, and has not been submitted for academic credit elsewhere or previously, or produced independently of this course (e.g. for a third party such as your place of employment) and acknowledge that the assessor of this item may, for the purpose of assessing this item:\n",
        "\n",
        "1. Reproduce this assessment item and provide a copy to another member of the University; and/or\n",
        "\n",
        "2. Communicate a copy of this assessment item to a plagiarism checking service (which may then retain a copy of the assessment item on its database for the purpose of future plagiarism checking).\n",
        "\n",
        "**By writing you name and surname above, you certify that you have read and agreed to the honour pledge.**\n",
        "\n",
        "#####################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####################################################################################\n",
        "\n",
        "Double-click to write down your name and surname.\n",
        "\n",
        "**Name 2 and Surname 2:**\n",
        "\n",
        "**Honour Pledge** <p>\n",
        "    \n",
        "    \n",
        "Declaration: <p>\n",
        "    \n",
        "    \n",
        "I declare that this assessment item is my own work, except where acknowledged, and has not been submitted for academic credit elsewhere or previously, or produced independently of this course (e.g. for a third party such as your place of employment) and acknowledge that the assessor of this item may, for the purpose of assessing this item:\n",
        "\n",
        "1. Reproduce this assessment item and provide a copy to another member of the University; and/or\n",
        "\n",
        "2. Communicate a copy of this assessment item to a plagiarism checking service (which may then retain a copy of the assessment item on its database for the purpose of future plagiarism checking).\n",
        "\n",
        "**By wrting you name and surname above, you certify that you have read and agreed to the honour pledge.**\n",
        "\n",
        "#####################################################################################"
      ],
      "metadata": {
        "id": "7EORMEMxuhJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 1.  Health Data Science Scenario\n",
        "\n",
        "## 1.1. Research Question\n",
        "\n",
        "Our hospital has been very proactive in analysing data from its Electronic Medical Records (EMR). Through this analysis, we've made some interesting discoveries.\n",
        "\n",
        "We identified that readmitted patients are not only those who were sicker during their first admission but also those with less support after discharge or those without medical follow-up post-discharge.\n",
        "Readmitted patients experienced high levels of emotional stress.\n",
        "Readmitted patients were at a significantly higher risk of acquiring new infections while in the hospital.\n",
        "Readmissions are highly costly. Patients who were readmitted for the reasons mentioned above tended to be sicker than during their first admission, and their length of stay was significantly longer than during their first admission."
      ],
      "metadata": {
        "id": "hvLpFjsB9PYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our hospital has implemented a pilot program named \"Redesigning Discharge,\" which involves a \"specialised unit\" that coordinates patients' discharges. This pilot program has been running for a year.\n",
        "\n",
        "This \"specialised unit\" is composed of a team of doctors, nurses, physiotherapists, and occupational therapists.\n",
        "\n",
        "The program consists of two main innovations.\n",
        "\n",
        "1. In the first part of the program, the doctors conduct a new discharge assessment protocol using innovative evidence-based tools to help them decide whether patients are ready to return to their usual place of residence or if it would be more advisable to transfer them to an intermediate or short-term care facility. As such, this program is set to replace the previous protocol concerning where patients should be discharged.\n",
        "\n",
        "2. The second part of the program includes a group of nurses, physiotherapists, and occupational therapists who visit patients at home or in the intermediate facility after discharge. The frequency of these visits is determined by an assessment conducted prior to discharge, averaging about five visits per patient. Among other things, the team's tasks include ensuring proper wound healing, checking medication compliance, coordinating with a general practitioner or the medical team at the intermediate facility, and assessing the patient's ability to perform basic daily activities such as navigating their environment, using the toilet, and showering. Furthermore, the specialised unit maintains regular telephone contact with patients to check on their well-being. Patients are also encouraged to reach out to the unit if they need any assistance.\n",
        "\n",
        "This pilot program has been very successful and it has been welcomed by all the stakeholders. Among other things, the program has significantly reduced the number of hospital readmissions. Moreover, the operating costs for this specialised unit have proven to be considerably lower than the costs associated with readmissions"
      ],
      "metadata": {
        "id": "zXDNhvVF9gAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terms of budget:\n",
        "\n",
        "1. The average cost of a day in the hospital is 6,000 dollars; readmitted patients tend to stay for an average of 4 days.\n",
        "\n",
        "2. An intervention by the specialised unit costs on average 2,000 dollars, which includes the cost of the average number of visits per patient, being 5 visits.\n",
        "\n",
        "3. The cost of an intermediate facility is not considered, as it's covered by Private Health Insurance or other Government Schemes. Additionally, our program is effectively 'donating' a team of medical professionals to these facilities. Therefore, we do not need to account for the cost of these intermediate facilities if a patient is discharged there.\n",
        "\n",
        "Our hospital is now prepared to implement \"Redesigning Discharge\" and extend the specialized unit service to all patients at risk of readmission. The challenge we face, however, is that we cannot predict in advance which patients are at risk of readmission. As such, we are currently unable to identify the specific patients we should be targeting"
      ],
      "metadata": {
        "id": "M1cJxrpO9sAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our research aims to address the following questions:\n",
        "\n",
        "1. Can we develop a machine learning algorithm that can predict the probability of a patient's readmission within 30 days before their discharge?\n",
        "\n",
        "2. How can we effectively communicate the performance and benefits of this algorithm to the hospital managers, enabling them to make an informed decision about its implementation?\n",
        "\n",
        "The main challenge we face is not only the development of an effective predictive algorithm, but also explaining its complexities in a clear, digestible manner for non-technical decision-makers."
      ],
      "metadata": {
        "id": "PlVCjmaWCpzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "k_dDoHDsl9X2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Instructions\n",
        "\n",
        "1.  We aim to develop a predictive model to forecast hospital readmissions within 30 days of discharge.\n",
        "\n",
        "> Consider the next points:\n",
        "\n",
        "> The predictive model will be run prior to discharge, and before a decision has been made regarding the need for the specialized unit or the place of discharge.\n",
        "\n",
        "> This forecast will primarly aid doctors and other clinicians in making a final decision about whether a patient will need the \"specialised unit\" or not.\n",
        "\n",
        "> In addition, as part of the new protocol, this forecast will also help decide whether the patient should return to their usual place of residence or be transferred to an intermediate facility. This new protocol is set to replace the previous one concerning where patients should be discharged.\n",
        "\n",
        "> We plan to use historical data from the hospital for this purpose. Unfortunately, the historical data with which we have been provided doesn't include any record of the pilot study that ran for a year, which could have assisted in training our model.\n",
        "\n",
        "\n",
        "2. Review the research questions and make the appropriate decisions for building this predictive model, in accordance with the research question text.\n",
        "\n",
        "\n",
        "3.   Thoroughly review and study the data provided. Please pay close attention to the data dictionary (PDF inside the data folder) and revisit the plots and graphs created during weeks 1, 2, and 3.\n",
        "\n",
        "4. Given that the hospital has already provided the data, we'll bypass the following steps in the health data science workflow (refer to the image below): Step 3 and substeps 3a,3b,3c,3d,3e: Data Gathering.\n",
        "\n",
        "5. In Step 4, substep 4a (Data visualization), visualize the data in your drafts, but do not include the graphs in your final submission.\n",
        "\n",
        "6. The hospital aims to capture as many \"readmissions\" as possible (true positives), even if this moderately increases the number of false positives within reason (i.e., patients not at risk of readmission classified as such). However, be mindful that the hospital does not have unlimited resources. An excessive number of patients identified as at-risk could inflate the operational costs of the \"specialised unit\" beyond sustainable levels.\n",
        "\n",
        "7. The data scientists at the hospital have asked that you only consider the Logistic Regression and Random Forest machine learning techniques.\n",
        "\n",
        "8. Design various machine learning algorithms with different hyperparameters. Select one and provide a rationale for your choice.\n",
        "\n",
        "9. Use the classification_report and confusion matrix metrics for model evaluation. If you use other metrics such as the ROC curve, do not include them in your final submission.\n",
        "\n",
        "10. Justification for your decisions is crucial. Provide a one or two sentence explanation for each section preceding the relevant Python code block. You are encouraged to use \"Sanity Checks\" during the construction of the algorithms. Please do not include them in your final submission.\n",
        "\n",
        "11. Ensure clear labels for printed results and briefly detail the steps followed.\n",
        "\n",
        "12. Remember to comment and document your code thoroughly, as this will likely serve as a foundation for team-based algorithm development in the future.\n",
        "\n",
        "13. Format: Jupyter Notebook.\n",
        "\n",
        "14. Programming Language: Python.\n",
        "\n",
        "15. Submission: Upload the Jupyter Notebook to the designated section in OpenLearning and on your GitHub space. Submissions will close precisely at the deadline.\n",
        "\n",
        "16. Only submit the final version of your document.\n",
        "\n",
        "17. Include your first and last names in the document's title. For example: Final-Assignment-AnnXu-MichaelRoss.ipynb\n",
        "\n",
        "18. Each question is worth 1 mark, except question 8, which is worth 2 marks.\n",
        "\n",
        "19. Marks will be deducted for failure to follow the previous instructions.\n",
        "\n",
        "20. Refer to the provided [rubric](https://unsw-my.sharepoint.com/:w:/g/personal/z3368601_ad_unsw_edu_au/EYaMoVWZ20hFoj9R8hL2PIIB4-ACN6c4bf4uCI66gzpEqA?e=tUJZiB).\n",
        "\n"
      ],
      "metadata": {
        "id": "CI9JCYKb-6tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=105SGqeyo8RgLhSO8mN7ZE5OsG0YiLPKt)"
      ],
      "metadata": {
        "id": "9wK1oQbhq5hX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Late Submission Penalty\n",
        "\n",
        "UNSW has a [standard](https://www.unsw.edu.au/arts-design-architecture/student-life/resources-support/protocols-guidelines)  late submission penalty of:\n",
        "\n",
        "\n",
        "*   5% per day,\n",
        "*   for all assessments where a penalty applies,\n",
        "*   capped at five days (120 hours) from the assessment deadline, after which a student cannot submit an assessment,\n",
        "*   and no permitted variation.\n",
        "\n",
        "Students are expected to manage their time to meet deadlines and to request extensions as early as possible before the deadline."
      ],
      "metadata": {
        "id": "Z9Yo-Q0QKhSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4. Marks and Feedback\n",
        "\n",
        "Per UNSW's policy, the marks and feedback of this assignment will be released after UNSW releases the final marks."
      ],
      "metadata": {
        "id": "a_aTlwYkKynH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3eE8VXdpl_I2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. Provided Python Code"
      ],
      "metadata": {
        "id": "2n7dR4_xLlk-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "skbhUSeQiKQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1e328c-d7ff-46be-e729-5ee935e7e533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing:  {'grid', 'shap'}\n"
          ]
        }
      ],
      "source": [
        "# check required libraries are installed if not calling system to install\n",
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "\n",
        "required = {'numpy', 'pandas', 'plotnine', 'matplotlib', 'seaborn',\n",
        "            'grid', 'shap', 'scikit-learn'}\n",
        "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
        "missing = required - installed\n",
        "\n",
        "if missing:\n",
        "    print('Installing: ', missing)\n",
        "    python = sys.executable\n",
        "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
        "# delete unwanted variables\n",
        "del required\n",
        "del installed\n",
        "del missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y8p62DC4iKQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378e5ae3-0315-4715-ec93-4a5b138a342c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "# We do not need to run this cell if you are not running this notebook in Google Colab\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive # import drive from Gogle colab\n",
        "    root = '/content/drive'     # default location for the drive\n",
        "    # print(root)                 # print content of ROOT (Optional)\n",
        "    drive.mount(root)\n",
        "else:\n",
        "    print('Not running on CoLab')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the project paths and the paths according to where you have placed your files:"
      ],
      "metadata": {
        "id": "T70EJU8pAzeY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kRNGzaEjiKQc"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    # EDIT THE PROJECT PATH IF DIFFERENT WITH YOUR ONE\n",
        "    project_path = Path(root) / 'MyDrive' / 'HDAT9500' / 'final-assignment'\n",
        "\n",
        "    # OPTIONAL - set working directory according to your google drive project path\n",
        "    # import os\n",
        "    # Change directory to the location defined in project_path\n",
        "    # os.chdir(project_path)\n",
        "else:\n",
        "    project_path = Path()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "Function to plot the confusion matrix:\n"
      ],
      "metadata": {
        "id": "58McxBL6Angl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(confusion_matrix):\n",
        "  # visualise the confusion matrix\n",
        "  labels = ['No', 'Yes']\n",
        "  ax = plt.subplot()\n",
        "  sns.heatmap(confusion_matrix, annot = True, fmt = '.0f', ax = ax, cmap = 'viridis')\n",
        "\n",
        "  # labels, titles and ticks\n",
        "  ax.set_xlabel('Predicted labels')\n",
        "  ax.set_ylabel('True labels')\n",
        "  ax.set_title('Confusion Matrix')\n",
        "  ax.xaxis.set_ticklabels(labels)\n",
        "  ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "ptWoRBD1os1T"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ANok5FMeLs8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 2. Questions:"
      ],
      "metadata": {
        "id": "rixnC6G4Lvtu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbpJocChpcTR"
      },
      "source": [
        "## Question 1: Docstring\n",
        "\n",
        "Create a docstring that includes the following:\n",
        "\n",
        "1. Purpose: The top-level aim of our program. (Please limit this to 50 words).\n",
        "2. Author(s)\n",
        "3. Dates\n",
        "4. List of Variables, Constants, and Functions: Describe how each one is used in the program. Ensure that you choose informative variable names and thoroughly document your program (both through docstrings and comments). When required, units should accompany the variables. The list of variables must be written in different sections: General, Question 1, Question 2, ..., Question 9. For the list of variables within each section, list the variables, constants, and functions in alphabetical order.\n",
        "5. Method: The \"Method\" section in a docstring typically refers to the approach or algorithm used in the program or function. Here, you would describe the sequence of operations or steps your code follows to accomplish its goal.\n",
        "\n",
        "Structure your docstring into distinct sections, with one section per point listed above.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2zvhr_epcTS"
      },
      "source": [
        "<b> 1. Purpose: The aim of our program:</b>\n",
        "\n",
        "################################################################################\n",
        "\n",
        "(double-click here)\n",
        "\n",
        "\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[...]"
      ],
      "metadata": {
        "id": "YriqPVQpS3Bp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3wGayW7marI"
      },
      "source": [
        "<b> 4. List of variables and constants in alphabetical order:</b>\n",
        "\n",
        "################################################################################\n",
        "\n",
        "(double-click here)\n",
        "For example:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<b> General: </b>\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "<b> Question 1: </b>\n",
        "\n",
        "* `variable_1`: description\n",
        "* `CONSTANT`: description\n",
        "* ...\n",
        "\n",
        "---\n",
        "\n",
        "(...)\n",
        "\n",
        "---\n",
        "<b> Question 4: Training, and hyper-parameter tuning of the Logistic Regression model.</b>\n",
        "\n",
        "* `variable_10`: description\n",
        "* `CONSTANT`: description\n",
        "* ...\n",
        "\n",
        "---\n",
        "\n",
        "<b>Question 5: Evaluation of the Logistic Regression: </b>\n",
        "\n",
        "* `confusion_LR_test`: confusion matrix derived from `y_test` and `y_pred_LR_test` for the logistic regression model `grid_search_LR` evaluated on the test set.\n",
        "* `confusion_RF_test`: confusion matrix derived from `y_test` and `y_pred_RF_test` for the random forest model `grid_search_RF` evaluated on the test set.\n",
        "\n",
        "---\n",
        "\n",
        "<b>Question 6: ... </b>\n",
        "\n",
        "* `variable_200`: description\n",
        "* ...\n",
        "---\n",
        "\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ew1S59Vj1l2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Question 2: Read and check the pickle file provided. Prepare the data so it can be used by the algorithms that you are going to create.\n",
        "---"
      ],
      "metadata": {
        "id": "DmqPFyIbnJci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> Rationale: What are you doing to solve this question? - 75 word count limit:</b>\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "Firstly, set up the path and read the data by using the function \"pickle.load\".\n",
        "\n",
        "Secondly, seperate the data into \"X\" and \"y\". (With and without the column \"readmission\")\n",
        "\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "1AogtSxHxEW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python code here (15 lines limit, 1 cell limit)\n",
        "import pickle\n",
        "import pandas as pd\n",
        "pickle_data_path = Path(project_path) / 'hospital_data_final_assignment.pickle'\n",
        "with open(pickle_data_path, \"rb\") as data:\n",
        "  hospital = pickle.load(data)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X = hospital.drop(['readmission'], axis = 1)\n",
        "y = hospital[['readmission']].values\n",
        "\n",
        "# Sanity check\n",
        "display(X[:][:5])\n",
        "X.shape\n",
        "\n",
        "# Sanity Checks:\n",
        "print('******************************************')\n",
        "print('y - Yes values =', sum(i =='yes' for i in y))\n",
        "print('y - No values =', sum(i =='no' for i in y))\n",
        "print('******************************************\\n')\n",
        "\n",
        "# Create y_binary\n",
        "y_binary = [0 if x=='no' else 1 for x in y]\n",
        "\n",
        "# Sanity Checks:\n",
        "print('\\n******************************************')\n",
        "print('y_binary - 1 values =', sum(i ==1 for i in y_binary))\n",
        "print('y_binary - 0 values =', sum(i ==0 for i in y_binary))\n",
        "print('******************************************')"
      ],
      "metadata": {
        "id": "DJJoTVRw049e",
        "outputId": "ccfc91e1-5f19-4c76-cb71-30292bd02ab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   admission_id  patient_id  los  Age  number_diagnoses  num_lab_procedures  \\\n",
              "0      62781276      360576    2   79                 9                  38   \n",
              "1      49223976     8151831    5   59                 8                  49   \n",
              "2     210634308    90219069    2   33                 5                  62   \n",
              "3     163620402    54294840    6   42                 9                  77   \n",
              "4      69055020     1634688    1   62                 7                  13   \n",
              "\n",
              "   num_procedures  num_medications  number_emergency  number_inpatient  ...  \\\n",
              "0               0               12                 0                 0  ...   \n",
              "1               0               16                 0                 0  ...   \n",
              "2               0               15                 1                 0  ...   \n",
              "3               0               30                 0                 0  ...   \n",
              "4               5                6                 0                 0  ...   \n",
              "\n",
              "   admission_source_grouped_Not available/Null  \\\n",
              "0                                            0   \n",
              "1                                            0   \n",
              "2                                            0   \n",
              "3                                            0   \n",
              "4                                            0   \n",
              "\n",
              "   admission_source_grouped_Other  \\\n",
              "0                               0   \n",
              "1                               0   \n",
              "2                               0   \n",
              "3                               0   \n",
              "4                               0   \n",
              "\n",
              "   admission_source_grouped_Physician Referral  \\\n",
              "0                                            0   \n",
              "1                                            0   \n",
              "2                                            0   \n",
              "3                                            0   \n",
              "4                                            0   \n",
              "\n",
              "   admission_source_grouped_Transfer from SNF  \\\n",
              "0                                           0   \n",
              "1                                           0   \n",
              "2                                           0   \n",
              "3                                           0   \n",
              "4                                           0   \n",
              "\n",
              "   admission_source_grouped_Transfer from another health care facility  \\\n",
              "0                                                  0                     \n",
              "1                                                  0                     \n",
              "2                                                  0                     \n",
              "3                                                  0                     \n",
              "4                                                  0                     \n",
              "\n",
              "   admission_type_grouped_Elective  admission_type_grouped_Emergency  \\\n",
              "0                                1                                 0   \n",
              "1                                1                                 0   \n",
              "2                                1                                 0   \n",
              "3                                1                                 0   \n",
              "4                                1                                 0   \n",
              "\n",
              "   admission_type_grouped_Not Available/Null  \\\n",
              "0                                          0   \n",
              "1                                          0   \n",
              "2                                          0   \n",
              "3                                          0   \n",
              "4                                          0   \n",
              "\n",
              "   admission_type_grouped_Trauma Centre  admission_type_grouped_Urgent  \n",
              "0                                     0                              0  \n",
              "1                                     0                              0  \n",
              "2                                     0                              0  \n",
              "3                                     0                              0  \n",
              "4                                     0                              0  \n",
              "\n",
              "[5 rows x 71 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-cc8c80d8-d8f4-4811-a87d-1dfa3668906a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>admission_id</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>los</th>\n",
              "      <th>Age</th>\n",
              "      <th>number_diagnoses</th>\n",
              "      <th>num_lab_procedures</th>\n",
              "      <th>num_procedures</th>\n",
              "      <th>num_medications</th>\n",
              "      <th>number_emergency</th>\n",
              "      <th>number_inpatient</th>\n",
              "      <th>...</th>\n",
              "      <th>admission_source_grouped_Not available/Null</th>\n",
              "      <th>admission_source_grouped_Other</th>\n",
              "      <th>admission_source_grouped_Physician Referral</th>\n",
              "      <th>admission_source_grouped_Transfer from SNF</th>\n",
              "      <th>admission_source_grouped_Transfer from another health care facility</th>\n",
              "      <th>admission_type_grouped_Elective</th>\n",
              "      <th>admission_type_grouped_Emergency</th>\n",
              "      <th>admission_type_grouped_Not Available/Null</th>\n",
              "      <th>admission_type_grouped_Trauma Centre</th>\n",
              "      <th>admission_type_grouped_Urgent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>62781276</td>\n",
              "      <td>360576</td>\n",
              "      <td>2</td>\n",
              "      <td>79</td>\n",
              "      <td>9</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49223976</td>\n",
              "      <td>8151831</td>\n",
              "      <td>5</td>\n",
              "      <td>59</td>\n",
              "      <td>8</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>210634308</td>\n",
              "      <td>90219069</td>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>163620402</td>\n",
              "      <td>54294840</td>\n",
              "      <td>6</td>\n",
              "      <td>42</td>\n",
              "      <td>9</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69055020</td>\n",
              "      <td>1634688</td>\n",
              "      <td>1</td>\n",
              "      <td>62</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã 71 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc8c80d8-d8f4-4811-a87d-1dfa3668906a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e5cdf5d0-ff40-4607-804d-bb642e2e2557\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e5cdf5d0-ff40-4607-804d-bb642e2e2557')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e5cdf5d0-ff40-4607-804d-bb642e2e2557 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc8c80d8-d8f4-4811-a87d-1dfa3668906a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc8c80d8-d8f4-4811-a87d-1dfa3668906a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "y - Yes values = [11919]\n",
            "y - No values = [57348]\n",
            "******************************************\n",
            "\n",
            "\n",
            "******************************************\n",
            "y_binary - 1 values = 11919\n",
            "y_binary - 0 values = 57348\n",
            "******************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "1gsmCMIJ9oQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Question 3: Divide the data into 80% for training and 20% for testing, using a random seed of 30. Set the other hyperparameters as you deem appropriate.\n",
        "---\n"
      ],
      "metadata": {
        "id": "PRlUipB2-nMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> Rationale: What are you doing to solve this question?- 75 word count limit:</b>\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "We use the function \"train_test_split\" to divide the data. The hyperparameter will include the optional argument 'stratify = y' to preserve the ratio between readmission = NO to readmission = YES.\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "7HjTXSR6-4cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python code here (2 lines limit, and 1 cell limit)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, stratify = y, test_size=0.2,random_state=30)"
      ],
      "metadata": {
        "id": "5LeXrTXc-4cR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZcRSCX5s1kPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Question 4: Train and tune the hyperparameters of the Logistic Regression model.\n",
        "\n",
        "Hyper-parameters:\n",
        "\n",
        "- `C` values: 10, 100.\n",
        "- `class_weight`: only two pairs. Choose one of these two combinations and explain why.\n",
        "\n",
        "    * A weight of (80% for class 1, 20% for class 0) and (70% for class 1, 30% for class 0)\n",
        "    * A weight of (80% for class 0, 20% for class 1) and (70% for class 0, 30% for class 1).\n",
        "\n",
        "- `penalty` values: elasticnet, None\n",
        "- 3-fold cross-validation for the grid search.\n",
        "- `f1` as the score to choose the best model in the grid search.\n",
        "- `n_jobs`=-1.\n",
        "- do not include the heatmaps in the final submission.\n",
        "- do not change these hyper-parameters.\n",
        "- keep the remaining set of hyper-parameters in the default state.\n",
        "---\n"
      ],
      "metadata": {
        "id": "b3v2JXmp1o5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> Rationale: What are you doing to solve this question?-100 word count limit:</b>\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "(double-click here)\n",
        "\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "p845NQAlAY-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python code here (15 lines limit, and 2 cells limit)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "standard_scaler = StandardScaler()\n",
        "\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# PipeLine:\n",
        "pipeln = Pipeline([('Transform', standard_scaler), ('Estimator', log_reg)])\n",
        "param_grid = {'Estimator__C': [10, 100],\n",
        "              'Estimator__class_weight': [{0: 0.8, 1: 0.2}, {0: 0.7, 1: 0.3}],\n",
        "              'Estimator__penalty': ['elastinet','none']}\n",
        "grid_search = GridSearchCV(pipeln, param_grid, cv = 3, scoring='f1', n_jobs=-1)\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
        "print(\"Best cross-validation score: {:.4f}\".format(grid_search.best_score_))"
      ],
      "metadata": {
        "id": "-ixDi9nvAY-d",
        "outputId": "e73358de-edcf-4968-9b98-ddb3d05241fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "12 fits failed out of a total of 24.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "8 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'none' (deprecated), 'elasticnet', 'l1'} or None. Got 'elastinet' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "4 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 405, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'l2', 'elasticnet', 'l1'} or None. Got 'elastinet' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.89614437        nan 0.91361954        nan 0.89614437\n",
            "        nan 0.91361954]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'Estimator__C': 10, 'Estimator__class_weight': {0: 0.7, 1: 0.3}, 'Estimator__penalty': 'none'}\n",
            "Best cross-validation score: 0.9136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "param_grid = param_grid = {\n",
        "    'C': [10, 100],\n",
        "    'class_weight': [{0: 0.8, 1: 0.2}, {0: 0.7, 1: 0.3}],\n",
        "    'penalty': ['elasticnet', 'none']\n",
        "}\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv = 3, scoring='f1', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
        "print(\"Best cross-validation score: {:.4f}\".format(grid_search.best_score_))"
      ],
      "metadata": {
        "id": "kQr3kcNkznr7",
        "outputId": "57a5f50b-4d6e-4366-eaf6-5c74afde57bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "12 fits failed out of a total of 24.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "12 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan  0. nan  0. nan  0. nan  0.]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 10, 'class_weight': {0: 0.8, 1: 0.2}, 'penalty': 'none'}\n",
            "Best cross-validation score: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "98-HHV0DNkkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Question 5: Evaluate the Logistic Regression model on both the training and test sets. Use the `plot_confusion_matrix(confusion_matrix)` function provided above to display the results.\n",
        "---"
      ],
      "metadata": {
        "id": "y2BLfWf9NmWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> Rationale: Why are we evaluating the model in the training set? Why are we evaluating the model in the test set? What are you doing to solve this question?- 120 word count limit:</b>\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "(double-click here)\n",
        "\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "T0ZoopThNyaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python code here (10 lines limit, and 2 cells limit)\n"
      ],
      "metadata": {
        "id": "L1GEJ8kGNyaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CTIi2cd1yugI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Question 6: Train and tune the hyperparameters of the of the Random Forest model.  \n",
        "\n",
        "Fixed hyper-parameters (do not change the values of these hyper-parameters):\n",
        "\n",
        "- `n_estimators`: 125, 150\n",
        "- `class_weight`: Only two pairs. Choose one of these two combinations (either combination 1 or combination 2) and explain why.\n",
        "1. A weight of (80% for class 1, 20% for class 0) and (70% for class 1, 30% for class 0)\n",
        "2.  A weight of (80% for class 0, 20% for class 1) and (70% for class 0, 30% for class 1).\n",
        "- 3-fold cross-validation for the grid search.\n",
        "- Select the score to choose the best model in the grid search.\n",
        "- `n_jobs`=-1\n",
        "- do not include the heatmaps in the final submission\n",
        "\n",
        "Other hyper-parameters:\n",
        "\n",
        "- `max_features`: 20, 30\n",
        "- `min_samples_split`: 20, 25\n",
        "- you can change the previous hyper-parameters (`max_features` and `min_samples_split`) or add other hyper-parameters if you wish. An explanation must be given to why you made that decision.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "iTQtpo_8yvX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> Rationale: What are you doing to solve this question?-150 word count limit:</b>\n",
        "\n",
        "\n",
        "################################################################################\n",
        "\n",
        "(double-click here)\n",
        "\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "fA5-7Qpe2SPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python code here (15 lines limit, and 2 cells limit)\n"
      ],
      "metadata": {
        "id": "9CHL7UB52SPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "_zu7iaT8AANM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Question 7: Evaluate the Random Forest model on both the training and test sets. Use the `plot_confusion_matrix(confusion_matrix)` function provided above to display the results.\n",
        "---"
      ],
      "metadata": {
        "id": "xwh91teY3VgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> Rationale: Why are we evaluating the model in the training set? Why are we evaluating the model in the test set? What are you doing to solve this question?- 120 word count limit:</b>\n",
        "\n",
        "################################################################################\n",
        "\n",
        "(double-click here)\n",
        "\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "hiHbV8Sf3VgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python code here (10 lines limit, and 2 cells limit)\n"
      ],
      "metadata": {
        "id": "Yk4wPAlV3VgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "4CsbaxoQ3VgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Question 8: Based on the research questions and instructions, determine which model, if any, you would choose. Justify whether or not you would deploy this model.\n",
        "---"
      ],
      "metadata": {
        "id": "eMBZph5HA6AN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> Rationale: 350 word count limit </b>\n",
        "\n",
        "################################################################################\n",
        "\n",
        "(double-click here)\n",
        "\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "AXP5G5nrA6AO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python code here (10 lines limit, and 2 cells limit)\n"
      ],
      "metadata": {
        "id": "heyMLNJtA6AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "l63_Jk0mA6AP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Question 9:  Implement SHAP for the final model and describe your observations. If no model was selected in question 8, provide a justification and choose one model specifically for this SHAP analysis. Conclude by commenting on the results.\n",
        "---"
      ],
      "metadata": {
        "id": "u0Wb9iHWASdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> Explanation of what you observe - 250 word count limit:</b>\n",
        "\n",
        "################################################################################\n",
        "\n",
        "(double-click here)\n",
        "\n",
        "\n",
        "################################################################################"
      ],
      "metadata": {
        "id": "1IlYvZ83ASda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python code here (10 lines limit, and 2 cells limit)\n"
      ],
      "metadata": {
        "id": "wh2VJms9ASda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hrD9unXPAZQL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYOVWp4ViKQq"
      },
      "source": [
        "Â© 2023 Copyright The University of New South Wales - CRICOS 00098G"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Final-Assignment-Name-Surname.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IbpJocChpcTR",
        "PRlUipB2-nMX",
        "b3v2JXmp1o5W",
        "y2BLfWf9NmWf",
        "iTQtpo_8yvX3",
        "xwh91teY3VgL",
        "eMBZph5HA6AN",
        "u0Wb9iHWASdT"
      ],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}